summary: Each snap app and hook is tracked via cgroups

details: |
    This test creates a snap process that suspends itself and ensures that it
    placed into the appropriate hierarchy under the pids cgroup.

prepare: |
    # This feature depends on the release-app-awareness feature
    snap set core experimental.refresh-app-awareness=true

    #shellcheck source=tests/lib/snaps.sh
    . "$TESTSLIB"/snaps.sh
    install_local test-snapd-sh

restore: |
    snap unset core experimental.refresh-app-awareness

execute: |
    # This test varies between Ubuntu 16.04, Ubuntu 18.04 and Fedora 31.
    # This combination exercises each of the three cases below.
    if grep -q -F "0::" < /proc/self/cgroup; then
        # Hybrid or pure v2 mode available.
        if [ "$(stat -f --print=%T /sys/fs/cgroup)" = "cgroup2fs" ]; then
            base_cg="/sys/fs/cgroup$(grep -F '0::' < /proc/self/cgroup | cut -d : -f 3)"
        else
            base_cg="/sys/fs/cgroup/unified$(grep -F '0::' < /proc/self/cgroup | cut -d : -f 3)"
        fi
    else
        # Only name=systemd available
        base_cg="/sys/fs/cgroup/systemd$(grep -F :name=systemd: < /proc/self/cgroup | cut -d : -f 3)"
    fi
    # Sanity check, this cgroup exists.
    test -d "$base_cg"


    trap 'killall test-snapd-sh || true' EXIT
    # Start a "sleep" process in the background
    #shellcheck disable=SC2016
    test-snapd-sh -c 'touch $SNAP_DATA/1.stamp && exec sleep 1h' &
    pid1=$!
    # Ensure that snap-confine has finished its task and that the snap process
    # is active. Note that we don't want to wait forever either.
    retry-tool -n 30 --wait 0.1 test -e /var/snap/test-snapd-sh/current/1.stamp
    # While the process is alive its PID can be seen in the cgroup.procs file
    # of the pid controller.
    MATCH "$pid1" < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"

    # Start a second process so that we can check adding tasks to an existing
    # control group.
    #shellcheck disable=SC2016
    test-snapd-sh -c 'touch $SNAP_DATA/2.stamp && exec sleep 1h' &
    pid2=$!
    retry-tool -n 30 --wait 0.1 test -e /var/snap/test-snapd-sh/current/2.stamp
    MATCH "$pid2" < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"

    # When the process terminates the control group is updated and the task no
    # longer registers there.
    kill "$pid1"
    wait "$pid1" || true  # wait returns the exit code and we kill the process
    MATCH -v "$pid1" < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"

    kill "$pid2"
    wait "$pid2" || true  # same as above
    MATCH -v "$pid2" < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"

    # If a snap command forks a child process it is also tracked.
    #shellcheck disable=SC2016
    test-snapd-sh -c 'touch $SNAP_DATA/3.stamp && sleep 1h' &
    pid3=$!

    # Ensure that snap-confine has finished its task and that the snap process
    # is active. Note that we don't want to wait forever either.
    retry-tool -n 30 --wait 0.1 test -e /var/snap/test-snapd-sh/current/3.stamp
    # While the process is alive its PID can be seen in the cgroup.procs file
    # of the current tracking hierarchy.
    MATCH "$pid3" < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"

    # Because the script above used "sleep 1h" instead of "exec sleep 1h" there
    # are now two processes: the shell and sleep.
    test "$(wc -l < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs")" -eq 2
    kill "$pid3"
    test "$(wc -l < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs")" -eq 1
    # Kill the remaining cgroup process.
    while read -r pid; do
        kill "$pid"
    done < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs"
    wait "$pid3" || true  # same as above
    test "$(wc -l < "$base_cg/snap.test-snapd-sh.test-snapd-sh/cgroup.procs")" -eq 0

summary: Build snap in armhf architecture

details: |
  Verifies that snapd can be built in armhf architecture.

backends: [openstack-arm]

environment:
  VERSION/noble: 24.04
  VERSION/jammy: 22.04
  VERSION/focal: 20.04
  IMAGE_URL: https://cloud-images.ubuntu.com/releases/$VERSION/release/ubuntu-$VERSION-server-cloudimg-armhf.img  
  KERNEL_URL: https://cloud-images.ubuntu.com/releases/$VERSION/release/unpacked/ubuntu-$VERSION-server-cloudimg-armhf-vmlinuz-generic
  INITRD_URL: https://cloud-images.ubuntu.com/releases/$VERSION/release/unpacked/ubuntu-$VERSION-server-cloudimg-armhf-initrd-generic

  SERVICE_NAME: nested-vm
  USER: root
  PASSWORD: ubuntu
  PORT: 2222

prepare: |
  # Install dependencies
  apt update
  apt install -y qemu-kvm cloud-image-utils sshpass

  # Get the image
  wget "$IMAGE_URL"
  IMAGE_FILE="$PWD/$(basename "$IMAGE_URL")"
  IMAGE_FILE_RAW="${IMAGE_FILE}.raw"

  # Get the kernel (we need it to be able to append the cmdline)
  wget "$KERNEL_URL"
  KERNEL_FILE="$PWD/$(basename "$KERNEL_URL")"
  
  # Get the initrd
  wget "$INITRD_URL"
  INITRD_FILE="$PWD/$(basename "$INITRD_URL")"

  # Prepare the raw image
  qemu-img convert -f qcow2 -O raw "$IMAGE_FILE" "$IMAGE_FILE_RAW"
  qemu-img resize "$IMAGE_FILE_RAW" +6G
  rm -f ${IMAGE_FILE}

  # Generate the cloud init seed
  CLOUD_INIT_ISO="$PWD/seed.img"
  cloud-localds "$CLOUD_INIT_ISO" user-data meta-data

  create_and_start_unit() {
      local name=$1
      local start_line=$2

      printf '[Unit]\nDescription=Support for test %s\n[Service]\nType=simple\nExecStart=%s\n[Install]\nWantedBy=multi-user.target\n' "$name" "$start_line" > "/etc/systemd/system/$name.service"

      systemctl daemon-reload
      systemctl enable "$name"
      systemctl start "$name"    
  }

  check_connection() {
      sshpass -p "$PASSWORD" ssh -p "$PORT" -o ConnectTimeout=10 -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no "$USER"@localhost true
  }

  # Create the nested vm service
  create_and_start_unit nested-vm "qemu-system-arm \
    -M virt \
    -cpu cortex-a15 \
    -smp 4 \
    -m 8192 \
    -nographic \
    -kernel \"$KERNEL_FILE\" \
    -initrd \"$INITRD_FILE\" \
    -append \"root=/dev/vda1 console=ttyAMA0\" \
    -drive file=\"$IMAGE_FILE\".raw,format=raw,if=none,id=hd0 \
    -device virtio-blk-device,drive=hd0 \
    -drive file=\"$CLOUD_INIT_ISO\",format=raw,if=virtio \
    -netdev user,id=net0,hostfwd=tcp::\"$PORT\"-:22 \
    -device virtio-net-device,netdev=net0"

  # Wait until the nested vm service is active
  for i in $(seq 15); do
      if systemctl show -p ActiveState "$SERVICE_NAME" | MATCH "ActiveState=active"; then
          break
      fi
      sleep 2
  done
  systemctl show -p ActiveState "$SERVICE_NAME" | MATCH "ActiveState=active"

  # Wait until the nested vm is accessible through ssh
  for i in $(seq 30); do
      if check_connection; then
          echo "connection established"
          break
      else
          sleep 10
      fi
  done
  check_connection

restore: |
  systemctl stop "$SERVICE_NAME"

execute: |
  # Copy the current project to be used to test in the created vm
  TMPDIR="$(mktemp -d)"
  mkdir "$TMPDIR"/tests
  cp -f "$PROJECT_PATH"/spread.yaml "$TMPDIR"  
  cp -rf "$PROJECT_PATH"/tests/build-snapd  "$TMPDIR"/tests/build-snapd

  export "SPREAD_EXTERNAL_ADDRESS=localhost:$PORT"

  # Download spread and run the build-snapd test
  curl -s https://storage.googleapis.com/snapd-spread-tests/spread/spread-plus-arm64.tar.gz | tar -xz -C "$PROJECT_PATH"
  cd "$TMPDIR" && "$PROJECT_PATH/spread" external:ubuntu-"$VERSION"-armhf:tests/build-snapd
